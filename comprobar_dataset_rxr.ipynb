{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0: TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "# check GPU ok\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPUs available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YCjzPDaMSrhe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'base_dataset_builder' from 'lavis.datasets.builders.base_dataset_builder' (/mnt/nas2/GrimaRepo/fpcattan/blip2/LAVIS_nav/lavis/datasets/builders/base_dataset_builder.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n",
      "File \u001b[0;32m/mnt/nas2/GrimaRepo/fpcattan/blip2/LAVIS_nav/lavis/__init__.py:15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OmegaConf\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/nas2/GrimaRepo/fpcattan/blip2/LAVIS_nav/lavis/datasets/builders/__init__.py:125\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscrn_builders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiscrnImagePcBuilder, DiscrnAudioVideoBuilder\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# new RXR\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrxr_caption_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RXRCaptionBuilder\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m    129\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlipDiffusionFinetuneBuilder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOCOCapBuilder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRXRCaptionBuilder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m ]\n",
      "File \u001b[0;32m/mnt/nas2/GrimaRepo/fpcattan/blip2/LAVIS_nav/lavis/datasets/builders/rxr_caption_builder.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_dataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_dataset_builder\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     RXRCaptionDataset,\n\u001b[1;32m      5\u001b[0m     RXRCaptionEvalDataset,\n\u001b[1;32m      6\u001b[0m     RXRCaptionInstructDataset\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'base_dataset_builder' from 'lavis.datasets.builders.base_dataset_builder' (/mnt/nas2/GrimaRepo/fpcattan/blip2/LAVIS_nav/lavis/datasets/builders/base_dataset_builder.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from lavis.common.registry import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CcnYK1edSthQ"
   },
   "outputs": [],
   "source": [
    "# setup device to use\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lavis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ver dataset zoo\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlavis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_zoo\n\u001b[1;32m      4\u001b[0m dataset_names \u001b[38;5;241m=\u001b[39m dataset_zoo\u001b[38;5;241m.\u001b[39mget_names()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_names)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:971\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1373\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1239\u001b[0m, in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1227\u001b[0m, in \u001b[0;36m_recalculate\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1223\u001b[0m, in \u001b[0;36m_get_parent_path\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lavis'"
     ]
    }
   ],
   "source": [
    "# ver dataset zoo\n",
    "\n",
    "from lavis.datasets.builders import dataset_zoo\n",
    "dataset_names = dataset_zoo.get_names()\n",
    "print(dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eOh4qtdUiaR",
    "outputId": "be94bd37-3439-4d66-db3c-a64415dbb355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Architectures                  Types\n",
      "==================================================\n",
      "albef_classification           ve\n",
      "albef_feature_extractor        base\n",
      "albef_nlvr                     nlvr\n",
      "albef_pretrain                 base\n",
      "albef_retrieval                coco, flickr\n",
      "albef_vqa                      vqav2\n",
      "alpro_qa                       msrvtt, msvd\n",
      "alpro_retrieval                msrvtt, didemo\n",
      "blip_caption                   base_coco, large_coco\n",
      "blip_classification            base\n",
      "blip_feature_extractor         base\n",
      "blip_image_text_matching       base, large\n",
      "blip_nlvr                      nlvr\n",
      "blip_pretrain                  base\n",
      "blip_retrieval                 coco, flickr\n",
      "blip_vqa                       vqav2, okvqa, aokvqa\n",
      "blip2_opt                      pretrain_opt2.7b, pretrain_opt6.7b, caption_coco_opt2.7b, caption_coco_opt6.7b\n",
      "blip2_t5                       pretrain_flant5xl, pretrain_flant5xl_vitL, pretrain_flant5xxl, caption_coco_flant5xl\n",
      "blip2_feature_extractor        pretrain, pretrain_vitL, coco\n",
      "blip2                          pretrain, pretrain_vitL, coco\n",
      "blip2_image_text_matching      pretrain, pretrain_vitL, coco\n",
      "pnp_vqa                        base, large, 3b\n",
      "pnp_unifiedqav2_fid            \n",
      "img2prompt_vqa                 base\n",
      "clip_feature_extractor         ViT-B-32, ViT-B-16, ViT-L-14, ViT-L-14-336, RN50\n",
      "clip                           ViT-B-32, ViT-B-16, ViT-L-14, ViT-L-14-336, RN50\n",
      "gpt_dialogue                   base\n"
     ]
    }
   ],
   "source": [
    "# para sacar info de los modelos\n",
    "from lavis.models import model_zoo\n",
    "print(model_zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "xpykEeWFUPoq",
    "outputId": "9ff74471-387f-4e0d-9919-392364e79b65",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4532b2129a046a89ac9bf8963c1dcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f94e3167e3a448eac12b08504e19b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/9.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbc6692159b4a33bd086cb37b94ff12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e238878d3e46048756d318ebd7cc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7003bed64a2441c929fdad6029ee464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/6.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a004266da024782b86ed2df2ebffdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 23.65 GiB total capacity; 21.13 GiB already allocated; 69.31 MiB free; 21.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# cargar solo el modelo desde los pesos en checkpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblip2_t5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrain_flant5xxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/blip2_pretrained_flant5xxl.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/lavis/models/__init__.py:118\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, model_type, is_eval, device, checkpoint)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    116\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 579 (5 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/lavis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 23.65 GiB total capacity; 21.13 GiB already allocated; 69.31 MiB free; 21.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# cargar solo el modelo desde los pesos en checkpoint\n",
    "model = load_model(name=\"blip2_t5\", model_type=\"pretrain_flant5xxl\", is_eval=False, device=device, checkpoint='./models/blip2_pretrained_flant5xxl.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blip2T5(\n",
      "  (visual_encoder): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (24): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (25): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (26): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (27): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (28): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (29): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (30): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (31): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (32): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (33): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (34): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (35): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (36): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (37): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (38): Block(\n",
      "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
      "  (Qformer): BertLMHeadModel(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): None\n",
      "        (position_embeddings): None\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): None\n",
      "            (output): None\n",
      "            (intermediate_query): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output_query): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): None\n",
      "  )\n",
      "  (t5_model): T5ForConditionalGeneration(\n",
      "    (shared): Embedding(32128, 2048)\n",
      "    (encoder): T5Stack(\n",
      "      (embed_tokens): Embedding(32128, 2048)\n",
      "      (block): ModuleList(\n",
      "        (0): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (relative_attention_bias): Embedding(32, 32)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (17): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (18): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (19): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (20): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (21): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (22): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (23): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (decoder): T5Stack(\n",
      "      (embed_tokens): Embedding(32128, 2048)\n",
      "      (block): ModuleList(\n",
      "        (0): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (relative_attention_bias): Embedding(32, 32)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (17): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (18): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (19): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (20): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (21): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (22): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (23): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "                (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseGatedActDense(\n",
      "                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
      "                (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (act): GELUActivation()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (lm_head): Linear(in_features=2048, out_features=32128, bias=False)\n",
      "  )\n",
      "  (t5_proj): Linear(in_features=768, out_features=2048, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Fri Feb  2 13:26:09 2024\n",
      "Driver Version                            : 460.39\n",
      "CUDA Version                              : 11.2\n",
      "\n",
      "Attached GPUs                             : 7\n",
      "GPU 00000000:01:00.0\n",
      "    Product Name                          : TITAN RTX\n",
      "    Product Brand                         : Titan\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : 0320119063038\n",
      "    GPU UUID                              : GPU-c977e49c-aabb-86de-d96c-1ce7e0839398\n",
      "    Minor Number                          : 0\n",
      "    VBIOS Version                         : 90.02.23.00.01\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x100\n",
      "    GPU Part Number                       : 900-1G150-2500-000\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x01\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E0210DE\n",
      "        Bus Id                            : 00000000:01:00.0\n",
      "        Sub System Id                     : 0x12A310DE\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 3\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 8x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 12000 KB/s\n",
      "        Rx Throughput                     : 66000 KB/s\n",
      "    Fan Speed                             : 40 %\n",
      "    Performance State                     : P2\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Not Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 24220 MiB\n",
      "        Used                              : 24151 MiB\n",
      "        Free                              : 69 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 11 MiB\n",
      "        Free                              : 245 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 15 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 56 C\n",
      "        GPU Shutdown Temp                 : 94 C\n",
      "        GPU Slowdown Temp                 : 91 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 61.13 W\n",
      "        Power Limit                       : 280.00 W\n",
      "        Default Power Limit               : 280.00 W\n",
      "        Enforced Power Limit              : 280.00 W\n",
      "        Min Power Limit                   : 100.00 W\n",
      "        Max Power Limit                   : 320.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        SM                                : 1350 MHz\n",
      "        Memory                            : 6500 MHz\n",
      "        Video                             : 1260 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Max Clocks\n",
      "        Graphics                          : 2100 MHz\n",
      "        SM                                : 2100 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes\n",
      "        GPU instance ID                   : N/A\n",
      "        Compute instance ID               : N/A\n",
      "        Process ID                        : 8712\n",
      "            Type                          : C\n",
      "            Name                          : /home/fpcattan/.pyenv/versions/3.8.18/envs/lavis_env/bin/python3.8\n",
      "            Used GPU Memory               : 22735 MiB\n",
      "        GPU instance ID                   : N/A\n",
      "        Compute instance ID               : N/A\n",
      "        Process ID                        : 32920\n",
      "            Type                          : C\n",
      "            Name                          : python3\n",
      "            Used GPU Memory               : 1413 MiB\n",
      "\n",
      "GPU 00000000:04:00.0\n",
      "    Product Name                          : TITAN RTX\n",
      "    Product Brand                         : Titan\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : 0320419026867\n",
      "    GPU UUID                              : GPU-756eae9e-47fa-e71d-0e0b-4306628ab44e\n",
      "    Minor Number                          : 1\n",
      "    VBIOS Version                         : 90.02.23.00.01\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x400\n",
      "    GPU Part Number                       : 900-1G150-2500-000\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x04\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E0210DE\n",
      "        Bus Id                            : 00000000:04:00.0\n",
      "        Sub System Id                     : 0x12A310DE\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 0 KB/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 40 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 24220 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 24217 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 253 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 45 C\n",
      "        GPU Shutdown Temp                 : 94 C\n",
      "        GPU Slowdown Temp                 : 91 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 16.47 W\n",
      "        Power Limit                       : 280.00 W\n",
      "        Default Power Limit               : 280.00 W\n",
      "        Enforced Power Limit              : 280.00 W\n",
      "        Min Power Limit                   : 100.00 W\n",
      "        Max Power Limit                   : 320.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 300 MHz\n",
      "        SM                                : 300 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 540 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Max Clocks\n",
      "        Graphics                          : 2100 MHz\n",
      "        SM                                : 2100 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n",
      "GPU 00000000:08:00.0\n",
      "    Product Name                          : TITAN RTX\n",
      "    Product Brand                         : Titan\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : 0320219052168\n",
      "    GPU UUID                              : GPU-0ce6a2b0-6e4c-f8a7-4ee0-8f94333503cf\n",
      "    Minor Number                          : 2\n",
      "    VBIOS Version                         : 90.02.23.00.01\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x800\n",
      "    GPU Part Number                       : 900-1G150-2500-000\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x08\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E0210DE\n",
      "        Bus Id                            : 00000000:08:00.0\n",
      "        Sub System Id                     : 0x12A310DE\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 0 KB/s\n",
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 41 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 24220 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 24217 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 253 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 44 C\n",
      "        GPU Shutdown Temp                 : 94 C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GPU Slowdown Temp                 : 91 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 1.82 W\n",
      "        Power Limit                       : 280.00 W\n",
      "        Default Power Limit               : 280.00 W\n",
      "        Enforced Power Limit              : 280.00 W\n",
      "        Min Power Limit                   : 100.00 W\n",
      "        Max Power Limit                   : 320.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 300 MHz\n",
      "        SM                                : 300 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 540 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : 1350 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "    Max Clocks\n",
      "        Graphics                          : 2100 MHz\n",
      "        SM                                : 2100 MHz\n",
      "        Memory                            : 7001 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n",
      "GPU 00000000:09:00.0\n",
      "    Product Name                          : GeForce GTX 1080 Ti\n",
      "    Product Brand                         : GeForce\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : 0321317116165\n",
      "    GPU UUID                              : GPU-5d4d2e88-8f8a-8555-169c-4d7dc0a4da81\n",
      "    Minor Number                          : 3\n",
      "    VBIOS Version                         : 86.02.39.00.01\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x900\n",
      "    GPU Part Number                       : 900-1G611-0151-000\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.01.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x09\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1B0610DE\n",
      "        Bus Id                            : 00000000:09:00.0\n",
      "        Sub System Id                     : 0x120F10DE\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 0 KB/s\n",
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 26 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 11178 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 11176 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 254 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            Single Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "            Double Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "        Aggregate\n",
      "            Single Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "            Double Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 46 C\n",
      "        GPU Shutdown Temp                 : 96 C\n",
      "        GPU Slowdown Temp                 : 93 C\n",
      "        GPU Max Operating Temp            : N/A\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 11.45 W\n",
      "        Power Limit                       : 250.00 W\n",
      "        Default Power Limit               : 250.00 W\n",
      "        Enforced Power Limit              : 250.00 W\n",
      "        Min Power Limit                   : 125.00 W\n",
      "        Max Power Limit                   : 300.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 139 MHz\n",
      "        SM                                : 139 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 544 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Max Clocks\n",
      "        Graphics                          : 1911 MHz\n",
      "        SM                                : 1911 MHz\n",
      "        Memory                            : 5505 MHz\n",
      "        Video                             : 1620 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n",
      "GPU 00000000:85:00.0\n",
      "    Product Name                          : GeForce RTX 2080 Ti\n",
      "    Product Brand                         : GeForce\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : N/A\n",
      "    GPU UUID                              : GPU-b38afc77-0165-f4cc-4b1d-c54edef069ab\n",
      "    Minor Number                          : 4\n",
      "    VBIOS Version                         : 90.02.17.00.7D\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x8500\n",
      "    GPU Part Number                       : N/A\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x85\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E0710DE\n",
      "        Bus Id                            : 00000000:85:00.0\n",
      "        Sub System Id                     : 0x23833842\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Tx Throughput                     : 0 KB/s\n",
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 0 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 11019 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 11016 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 253 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 47 C\n",
      "        GPU Shutdown Temp                 : 94 C\n",
      "        GPU Slowdown Temp                 : 91 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 11.67 W\n",
      "        Power Limit                       : 260.00 W\n",
      "        Default Power Limit               : 260.00 W\n",
      "        Enforced Power Limit              : 260.00 W\n",
      "        Min Power Limit                   : 100.00 W\n",
      "        Max Power Limit                   : 338.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 300 MHz\n",
      "        SM                                : 300 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 540 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Max Clocks\n",
      "        Graphics                          : 2175 MHz\n",
      "        SM                                : 2175 MHz\n",
      "        Memory                            : 7000 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n",
      "GPU 00000000:88:00.0\n",
      "    Product Name                          : GeForce RTX 2080 SUPER\n",
      "    Product Brand                         : GeForce\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : N/A\n",
      "    GPU UUID                              : GPU-8e5cca6c-862a-991d-756e-200b00b1b1d2\n",
      "    Minor Number                          : 5\n",
      "    VBIOS Version                         : 90.04.7A.40.1C\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x8800\n",
      "    GPU Part Number                       : N/A\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x88\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E8110DE\n",
      "        Bus Id                            : 00000000:88:00.0\n",
      "        Sub System Id                     : 0x3FFB1458\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 0 KB/s\n",
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 36 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 7982 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 7979 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 3 MiB\n",
      "        Free                              : 253 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 46 C\n",
      "        GPU Shutdown Temp                 : 100 C\n",
      "        GPU Slowdown Temp                 : 97 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 12.81 W\n",
      "        Power Limit                       : 250.00 W\n",
      "        Default Power Limit               : 250.00 W\n",
      "        Enforced Power Limit              : 250.00 W\n",
      "        Min Power Limit                   : 125.00 W\n",
      "        Max Power Limit                   : 250.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 300 MHz\n",
      "        SM                                : 300 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 540 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Max Clocks\n",
      "        Graphics                          : 2100 MHz\n",
      "        SM                                : 2100 MHz\n",
      "        Memory                            : 7751 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n",
      "GPU 00000000:89:00.0\n",
      "    Product Name                          : GeForce GTX 1080 Ti\n",
      "    Product Brand                         : GeForce\n",
      "    Display Mode                          : Disabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : 0320917084904\n",
      "    GPU UUID                              : GPU-b14cede7-b1b9-b254-e608-4555fa93c122\n",
      "    Minor Number                          : 6\n",
      "    VBIOS Version                         : 86.02.39.00.01\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x8900\n",
      "    GPU Part Number                       : 900-1G611-0151-000\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.01.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x89\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1B0610DE\n",
      "        Bus Id                            : 00000000:89:00.0\n",
      "        Sub System Id                     : 0x120F10DE\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 1\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 0 KB/s\n",
      "        Rx Throughput                     : 0 KB/s\n",
      "    Fan Speed                             : 23 %\n",
      "    Performance State                     : P8\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Not Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 11178 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 11176 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 254 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            Single Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "            Double Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "        Aggregate\n",
      "            Single Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "            Double Bit            \n",
      "                Device Memory             : N/A\n",
      "                Register File             : N/A\n",
      "                L1 Cache                  : N/A\n",
      "                L2 Cache                  : N/A\n",
      "                Texture Memory            : N/A\n",
      "                Texture Shared            : N/A\n",
      "                CBU                       : N/A\n",
      "                Total                     : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 41 C\n",
      "        GPU Shutdown Temp                 : 96 C\n",
      "        GPU Slowdown Temp                 : 93 C\n",
      "        GPU Max Operating Temp            : N/A\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 9.92 W\n",
      "        Power Limit                       : 250.00 W\n",
      "        Default Power Limit               : 250.00 W\n",
      "        Enforced Power Limit              : 250.00 W\n",
      "        Min Power Limit                   : 125.00 W\n",
      "        Max Power Limit                   : 300.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 139 MHz\n",
      "        SM                                : 139 MHz\n",
      "        Memory                            : 405 MHz\n",
      "        Video                             : 544 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Max Clocks\n",
      "        Graphics                          : 1911 MHz\n",
      "        SM                                : 1911 MHz\n",
      "        Memory                            : 5505 MHz\n",
      "        Video                             : 1620 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes                             : None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
